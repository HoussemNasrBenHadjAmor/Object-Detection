{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "#from torchvision.transforms import functional as F\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob as glob\n",
    "from lxml import etree, objectify\n",
    "import random\n",
    "from xml.etree import ElementTree as et\n",
    "from datasets import (\n",
    "    create_train_dataset, create_valid_dataset, \n",
    "    create_train_loader, create_valid_loader\n",
    ")\n",
    "from utils.transforms import (\n",
    "    get_train_transform, get_valid_transform,\n",
    "    get_train_aug\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the image and annotation directories\n",
    "train_images_path = '/teamspace/studios/this_studio/football-players-detection-9/train'\n",
    "train_labels_path = '/teamspace/studios/this_studio/football-players-detection-9/train'\n",
    "valid_images_path = '/teamspace/studios/this_studio/football-players-detection-9/valid'\n",
    "valid_labels_path = '/teamspace/studios/this_studio/football-players-detection-9/valid'\n",
    "test_images_path = '/teamspace/studios/this_studio/football-players-detection-9/test'\n",
    "test_labels_path = '/teamspace/studios/this_studio/football-players-detection-9/test'\n",
    "\n",
    "# Image dimensions\n",
    "width, height = 1920, 1080\n",
    "\n",
    "# Classes (ensure these are in the same order as used during training)\n",
    "classes = ['__background__', 'ball', 'goalkeeper', 'player', 'referee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/albumentations/core/composition.py:156: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = create_train_dataset(\n",
    "    train_images_path, train_labels_path, \n",
    "    width, height, classes\n",
    ")\n",
    "valid_dataset = create_valid_dataset(\n",
    "    valid_images_path, valid_labels_path, \n",
    "    width, height, classes\n",
    ")\n",
    "test_dataset = create_valid_dataset(\n",
    "    test_images_path, test_labels_path, \n",
    "    width, height, classes\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = create_train_loader(train_dataset, batch_size=64, num_workers=4)\n",
    "valid_loader = create_valid_loader(valid_dataset, batch_size=64, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_pipeline = A.Compose([\n",
    "    A.HorizontalFlip(p=0.4),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.1),\n",
    "    #A.CLAHE(clip_limit=2, p=0.2),  # Add CLAHE for better contrast control\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=30, p=0.4),\n",
    "    A.RandomCrop(width=450, height=450, p=0.4),\n",
    "    A.GaussianBlur(p=0.2),\n",
    "    A.HueSaturationValue(p=0.2),\n",
    "    A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.2),\n",
    "    A.OneOf([\n",
    "        A.RandomRain(p=0.2),\n",
    "        A.RandomSnow(p=0.2),\n",
    "        A.RandomFog(p=0.2),\n",
    "        A.RandomSunFlare(p=0.2)\n",
    "    ], p=0.5),  # Add weather augmentation with a 30% probability\n",
    "    #ToTensorV2(p=1.0)\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_augmented_image_and_labels(image, bboxes, class_labels, original_image_path, original_label_path, output_image_dir, output_label_dir, counter, class_mapping):\n",
    "    image_name = os.path.splitext(os.path.basename(original_image_path))[0]\n",
    "    augmented_image_name = f\"{image_name}_aug_{counter}.jpg\"\n",
    "    augmented_label_name = f\"{image_name}_aug_{counter}.xml\"\n",
    "    \n",
    "    augmented_image_path = os.path.join(output_image_dir, augmented_image_name)\n",
    "    augmented_label_path = os.path.join(output_label_dir, augmented_label_name)\n",
    "\n",
    "    # Convert the tensor image back to a NumPy array and scale pixel values if necessary\n",
    "    if torch.is_tensor(image):\n",
    "        image = image.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    # Ensure the image is in the range [0, 255]\n",
    "    if image.max() <= 1.0:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "    \n",
    "    cv2.imwrite(augmented_image_path, image)\n",
    "    \n",
    "    # Create the XML annotation\n",
    "    E = objectify.ElementMaker(annotate=False)\n",
    "    anno_tree = E.annotation(\n",
    "        E.folder(''),\n",
    "        E.filename(augmented_image_path),\n",
    "        E.path(augmented_image_path),\n",
    "        E.source(\n",
    "            E.database(\"Unknown\")\n",
    "        ),\n",
    "        E.size(\n",
    "            E.width(image.shape[1]),\n",
    "            E.height(image.shape[0]),\n",
    "            E.depth(image.shape[2])\n",
    "        ),\n",
    "        E.segmented(0),\n",
    "    )\n",
    "    \n",
    "    for bbox, class_label in zip(bboxes, class_labels):\n",
    "        xmin, ymin, xmax, ymax = bbox\n",
    "        class_name = class_mapping[int(class_label)]\n",
    "        obj = E.object(\n",
    "            E.name(class_name),\n",
    "            E.pose(\"Unspecified\"),\n",
    "            E.truncated(0),\n",
    "            E.difficult(0),\n",
    "            E.occluded(0),\n",
    "            E.bndbox(\n",
    "                E.xmin(int(xmin)),\n",
    "                E.ymin(int(ymin)),\n",
    "                E.xmax(int(xmax)),\n",
    "                E.ymax(int(ymax))\n",
    "            )\n",
    "        )\n",
    "        anno_tree.append(obj)\n",
    "\n",
    "    etree.ElementTree(anno_tree).write(augmented_label_path, pretty_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_augmentation(base_dir, output_dir, classes_to_augment, augmentation_pipeline, width, height, classes, class_mapping):\n",
    "    for folder in ['test', 'valid', 'train']:\n",
    "        image_dir = os.path.join(base_dir, folder)\n",
    "        label_dir = os.path.join(base_dir, folder)\n",
    "        #if folder == 'train':\n",
    "         #   dataset = create_train_dataset(image_dir, label_dir, width, height, classes, use_train_aug=False, mosaic=True)\n",
    "        #else:\n",
    "         #   dataset = create_valid_dataset(image_dir, label_dir, width, height, classes)\n",
    "\n",
    "        dataset = create_valid_dataset(image_dir, label_dir, width, height, classes)\n",
    "        output_image_dir = os.path.join(output_dir, folder)\n",
    "        output_label_dir = os.path.join(output_dir, folder)\n",
    "\n",
    "        os.makedirs(output_image_dir, exist_ok=True)\n",
    "        os.makedirs(output_label_dir, exist_ok=True)\n",
    "\n",
    "        for image, target in dataset:\n",
    "            image_path = target['image_path']\n",
    "            label_path = target['annot_path']\n",
    "\n",
    "            # Ensure the image is a NumPy array\n",
    "            if not isinstance(image, np.ndarray):\n",
    "                if torch.is_tensor(image):\n",
    "                    image = image.permute(1, 2, 0).cpu().numpy()\n",
    "                else:\n",
    "                    raise TypeError(\"Image must be a NumPy array or a torch tensor.\")\n",
    "\n",
    "            # Convert the image to uint8 if itâ€™s not\n",
    "            if image.dtype != np.uint8:\n",
    "                image = (image * 255).astype(np.uint8)\n",
    "\n",
    "            if any(cls in target['labels'].tolist() for cls in classes_to_augment):\n",
    "                for i in range(10):  # Number of augmentations per image\n",
    "                    try:\n",
    "                        augmented = augmentation_pipeline(image=image, bboxes=target['boxes'].tolist(), labels=target['labels'].tolist())\n",
    "                        augmented_image = augmented['image']\n",
    "                        augmented_bboxes = augmented['bboxes']\n",
    "                        augmented_class_labels = augmented['labels']\n",
    "\n",
    "                        # Convert augmented image to NumPy array if it's a tensor\n",
    "                        if isinstance(augmented_image, torch.Tensor):\n",
    "                            augmented_image = augmented_image.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "                        if len(augmented_bboxes) > 0 and len(augmented_class_labels) > 0:\n",
    "                            save_augmented_image_and_labels(augmented_image, augmented_bboxes, augmented_class_labels, image_path, label_path, output_image_dir, output_label_dir, i, class_mapping)\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f'Error during augmentation: {e}')\n",
    "\n",
    "    print(\"Augmentation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation complete.\n"
     ]
    }
   ],
   "source": [
    "# Image dimensions\n",
    "width, height = 1920, 1080\n",
    "\n",
    "# Classes (ensure these are in the same order as used during training)\n",
    "classes = ['__background__', 'ball', 'goalkeeper', 'player', 'referee']\n",
    "\n",
    "base_dir = '/teamspace/studios/this_studio/football-players-detection-9'\n",
    "output_dir = '/teamspace/studios/this_studio/football-players-detection-9-augmented'\n",
    "classes_to_augment = [1, 2, 3, 4]\n",
    "class_mapping = {\n",
    "    1: \"ball\",\n",
    "    2: \"goalkeeper\",\n",
    "    3: \"player\", \n",
    "    4: \"referee\"\n",
    "}\n",
    "process_augmentation(base_dir, output_dir, classes_to_augment, augmentation_pipeline, width, height, classes, class_mapping)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
